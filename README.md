# LLM_RAG_VectorDB
using VectorDB populated to help LLM generate answer


1. **Data** databricks-dolly-15k HuggingFace Dataset: Is an open-source dataset of instruction-following records generated by Databricks employees. It's designed for training large language models (LLMs), synthetic data generation, and data augmentation. The dataset includes various types of prompts and responses in categories like brainstorming, classification, closed QA, generation, information extraction, open QA, and summarization. <br>
2. **Vector DB - Chroma** as the Vector Store (Knowledge Base): We employ Chroma as our primary vector store, acting as the knowledge base for our bot.<br>
3. **Sentence Transformers for Semantic Search**: Specifically, we use the 'multi-qa-MiniLM-L6-cos-v1' model from Sentence Transformers, optimized for semantic search applications. This model is responsible for **generating embeddings that are stored in Chroma**.
<br>
4.**LLM - Falcon 7B Instruct Model**: Serving as our open-source generative model, Falcon 7B is a decoder-only model with 7 billion parameters. Developed by TII, it's trained on an extensive 1,500B tokens dataset, RefinedWeb, supplemented with curated corpora. Notably, Falcon 40B, its larger counterpart, ranks as the top large language model on Hugging Face's Open LLM Leaderboard.

![image](https://github.com/ShawnLiu119/LLM_RAG_VectorDB/assets/43327902/671682b7-b79a-4972-8b17-3121b7fd45c0)

