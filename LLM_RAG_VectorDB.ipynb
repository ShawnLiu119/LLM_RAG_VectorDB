{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOZfcREeGZrRJBKUbpkmSI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0407fc4f9d14ca7915ce0005715f995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e182362afed46ebaff925f046ad6504",
              "IPY_MODEL_21780d070b7343d7aeaa0b5e8e2a8d10",
              "IPY_MODEL_8d5c4312d4244e46aa1f64e690a291a1"
            ],
            "layout": "IPY_MODEL_4d0dd2fe51e64440b77fd8969c618660"
          }
        },
        "9e182362afed46ebaff925f046ad6504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08f3ce9d9bd943ff860e32b9045875b3",
            "placeholder": "​",
            "style": "IPY_MODEL_578075bf9bd9488eaacf6c19f91571e7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "21780d070b7343d7aeaa0b5e8e2a8d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc02dabc8e47455e985f72f7d9a889a6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e516d872963467196f34b8d02374c19",
            "value": 2
          }
        },
        "8d5c4312d4244e46aa1f64e690a291a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738807d97aa147258579cd083a4b9749",
            "placeholder": "​",
            "style": "IPY_MODEL_e7fbf95ce2ab4cffabf4526bdc85faaa",
            "value": " 2/2 [00:56&lt;00:00, 26.36s/it]"
          }
        },
        "4d0dd2fe51e64440b77fd8969c618660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f3ce9d9bd943ff860e32b9045875b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578075bf9bd9488eaacf6c19f91571e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc02dabc8e47455e985f72f7d9a889a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e516d872963467196f34b8d02374c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "738807d97aa147258579cd083a4b9749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7fbf95ce2ab4cffabf4526bdc85faaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShawnLiu119/LLM_RAG_VectorDB/blob/main/LLM_RAG_VectorDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A guick POC for LLM augmented with VectorDB**"
      ],
      "metadata": {
        "id": "bZdhkc3aXRk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Data** databricks-dolly-15k HuggingFace Dataset: Is an open-source dataset of instruction-following records generated by Databricks employees. It's designed for training large language models (LLMs), synthetic data generation, and data augmentation. The dataset includes various types of prompts and responses in categories like brainstorming, classification, closed QA, generation, information extraction, open QA, and summarization. <br>\n",
        "2. **Vector DB - Chroma** as the Vector Store (Knowledge Base): We employ Chroma as our primary vector store, acting as the knowledge base for our bot.<br>\n",
        "3. **Sentence Transformers for Semantic Search**: Specifically, we use the 'multi-qa-MiniLM-L6-cos-v1' model from Sentence Transformers, optimized for semantic search applications. This model is responsible for **generating embeddings that are stored in Chroma**.\n",
        "<br>\n",
        "4.**LLM - Falcon 7B Instruct Model**: Serving as our open-source generative model, Falcon 7B is a decoder-only model with 7 billion parameters. Developed by TII, it's trained on an extensive 1,500B tokens dataset, RefinedWeb, supplemented with curated corpora. Notably, Falcon 40B, its larger counterpart, ranks as the top large language model on Hugging Face's Open LLM Leaderboard."
      ],
      "metadata": {
        "id": "9B9pE1DrXX_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install h5py typing-extensions wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTU2lcQ_c1bA",
        "outputId": "8e66b01a-2920-4dc3-cb0c-cf39f1ce5d00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.11.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.43.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "transformers==4.30.2 \\\n",
        "torch==2.3.0 \\\n",
        "einops==0.6.1 \\\n",
        "accelerate==0.20.3 \\\n",
        "datasets==2.14.5 \\\n",
        "chromadb \\\n",
        "sentence-transformers==2.2.2\n",
        "\n",
        "# torch==2.0.1+cu118 \\ does not work\n",
        "#einops: ensor manipualtion"
      ],
      "metadata": {
        "id": "z0Rhn4KhXQhX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Knowledge Base - VectorDB"
      ],
      "metadata": {
        "id": "UMAsrH-Xbk-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load only the training split of the dataset\n",
        "train_dataset = load_dataset(\"databricks/databricks-dolly-15k\", split='train')\n",
        "\n",
        "# Filter the dataset to only include entries with the 'closed_qa' category -> must find answer from database\n",
        "closed_qa_dataset = train_dataset.filter(lambda example: example['category'] == 'closed_qa')\n",
        "\n",
        "print(closed_qa_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaMRWfCYaqOk",
        "outputId": "a9ea3d6b-2562-451e-9ac1-543a9fbb43c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'When did Virgin Australia start operating?', 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: generating word embeddings for each set of instructions and their respective contexts, integrating them into our vector database, ChromaDB.\n",
        "\n",
        "Chroma DB, an open-source vector storage system, excels in managing vector embeddings. It's tailored for applications like semantic search engines,\n",
        "<br>\n",
        "**Semantic search** is a search engine technology that interprets the meaning of words and phrases. The results of a semantic search will return content **matching the meaning of a query**, as **opposed to content that literally matches words** in the query. <br>\n",
        "multi-qa-MiniLM-L6-cos-v1: specifically trained for semantic search use cases\n"
      ],
      "metadata": {
        "id": "vLzW-mkveNBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class VectorStore:\n",
        "\n",
        "    def __init__(self, collection_name):\n",
        "       # Initialize the embedding model\n",
        "        self.embedding_model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1') #pre-assinged model\n",
        "        self.chroma_client = chromadb.Client()\n",
        "        self.collection = self.chroma_client.create_collection(name=collection_name)\n",
        "\n",
        "    # Method to populate the vector store with embeddings from a dataset\n",
        "    def populate_vectors(self, dataset):\n",
        "        for i, item in enumerate(dataset):\n",
        "            combined_text = f\"{item['instruction']}. {item['context']}\" #response here is not needed? all info could be found in context+instruction??\n",
        "            embeddings = self.embedding_model.encode(combined_text).tolist()\n",
        "            self.collection.add(embeddings=[embeddings], documents=[item['context']], ids=[f\"id_{i}\"])\n",
        "\n",
        "    # Method to search the ChromaDB collection for relevant context based on a query\n",
        "    def search_context(self, query, n_results=1):\n",
        "        query_embeddings = self.embedding_model.encode(query).tolist()\n",
        "        return self.collection.query(query_embeddings=query_embeddings, n_results=n_results)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "   # Initialize the handler with collection name\n",
        "    vector_store = VectorStore(\"knowledge-base\")\n",
        "\n",
        "    # Assuming closed_qa_dataset is defined and available\n",
        "    vector_store.populate_vectors(closed_qa_dataset)"
      ],
      "metadata": {
        "id": "37qDYOvmeMPZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what date is U.S. Memorial Day?\"\n",
        "\n",
        "vector_store.search_context(query, n_results=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4kgDLzqeML5",
        "outputId": "4e53f0b1-0e1f-4e77-dd1d-881e7ca86f8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['id_1336', 'id_1333']],\n",
              " 'distances': [[1.0965921878814697, 1.1642955541610718]],\n",
              " 'metadatas': [[None, None]],\n",
              " 'embeddings': None,\n",
              " 'documents': [['San Francisco Mayor Ed Lee declared January 26 as \"Original Joe\\'s Day\".',\n",
              "   'Independence Day (colloquially the Fourth of July) is a federal holiday in the United States commemorating the Declaration of Independence, which was ratified by the Second Continental Congress on July 4, 1776, establishing the United States of America.\\n\\nThe Founding Father delegates of the Second Continental Congress declared that the Thirteen Colonies were no longer subject (and subordinate) to the monarch of Britain, King George III, and were now united, free, and independent states. The Congress voted to approve independence by passing the Lee Resolution on July 2 and adopted the Declaration of Independence two days later, on July 4.\\n\\nIndependence Day is commonly associated with fireworks, parades, barbecues, carnivals, fairs, picnics, concerts, baseball games, family reunions, political speeches, and ceremonies, in addition to various other public and private events celebrating the history, government, and traditions of the United States. Independence Day is the national day of the United States.']],\n",
              " 'uris': None,\n",
              " 'data': None}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Is Google a public company?\"\n",
        "\n",
        "vector_store.search_context(query, n_results=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aFjPeEVeMIW",
        "outputId": "b9502bdf-0e93-4d2e-843b-e533a8e870c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['id_722', 'id_44']],\n",
              " 'distances': [[1.1779518127441406, 1.2146285772323608]],\n",
              " 'metadatas': [[None, None]],\n",
              " 'embeddings': None,\n",
              " 'documents': [[\"True Corporation Public Company Limited (TRUE) (Formerly: True Corporation Public Company Limited and Total Access Communication Public Company Limited) is a communications conglomerate in Thailand. It is a joint venture between Charoen Pokphand Group and Telenor, formed by the merger between the original True Corporation and DTAC in the form of equal partnership to create a new telecommunications company that can fully meet the needs of the digital age. True controls Thailand's largest cable TV provider, TrueVisions, Thailand's largest internet service provider True Online,[citation needed] Thailand's largest mobile operators, TrueMove H and DTAC TriNet, which is second and third only to AIS. and entertainment media including television, internet, online games, and mobile phones under the True Digital brand. As of August 2014, True, along with True Telecommunications Growth Infrastructure Fund, had a combined market capitalization of US$10 billion.[citation needed] TrueMove is also a partner of Vodafone Group. Charoen Pokphand Group and Telenor hold equal ownership of 30% of True's shares as of March 2023. It operates fixed-line (as a concessionaire of NT (formerly known as TOT)), wireless, cable TV, IPTV and broadband services.\",\n",
              "   'Disney is one of the biggest and best-known companies in the world, and has been ranked number 53 on the 2022 Fortune 500 list of biggest companies in the United States by revenue. Since its founding, the company has won 135 Academy Awards, 26 of which have been awarded to Walt. The company has been said to have produced some of the greatest films of all time, as well as revolutionizing the theme park industry. Disney has been criticized for supposed plagiarism, depicting racial stereotypes in the past, and both including and lacking LGBT-related elements in its films. The company, which has been public since 1940, trades on the New York Stock Exchange (NYSE) with ticker symbol DIS and has been a component of the Dow Jones Industrial Average since 1991. In August 2020, just under two-thirds of the stock was owned by large financial institutions.']],\n",
              " 'uris': None,\n",
              " 'data': None}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who is United State's President today\"\n",
        "\n",
        "vector_store.search_context(query, n_results=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zu9QZRveMGH",
        "outputId": "f79e2f92-b84b-4b46-c0c6-642b46d6ad1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['id_1075', 'id_48']],\n",
              " 'distances': [[0.8786306381225586, 1.061730980873108]],\n",
              " 'metadatas': [[None, None]],\n",
              " 'embeddings': None,\n",
              " 'documents': [['From Simple English Wikipedia, the free encyclopedia\\nPresident of the\\nUnited States of America\\nSeal of the President of the United States.svg\\nSeal of the President of the United States\\nFlag of the President of the United States.svg\\nFlag of the President of the United States\\nJoe Biden presidential portrait.jpg\\nIncumbent\\nJoe Biden\\nsince January 20, 2021\\nExecutive branch of the U.S. government\\nExecutive Office of the President\\nStyle\\t\\nMr. President\\n(informal)\\nThe Honorable\\n(formal)\\nHis Excellency\\n(diplomatic)\\nType\\t\\nHead of state\\nHead of government\\nAbbreviation\\tPOTUS\\nMember of\\t\\nCabinet\\nDomestic Policy Council\\nNational Economic Council\\nNational Security Council\\nResidence\\tWhite House\\nSeat\\tWashington, D.C.\\nAppointer\\tElectoral College\\nTerm length\\tFour years, renewable once\\nConstituting instrument\\tConstitution of the United States\\nInaugural holder\\tGeorge Washington\\nFormation\\tMarch 4, 1789\\n(234 years ago)\\nDeputy\\tVice President of the United States\\nSalary\\t$400,000 (annually)\\nWebsite\\twhitehouse.gov\\nThis article is part of a series on the\\nPolitics of the\\nUnited States of America\\nGreater coat of arms of the United States.svg\\nFederal Government\\nLegislature\\nExecutive\\nJudiciary\\nElections\\nPolitical parties\\nFederalism\\nOther countriesAtlas\\nvte\\nThe president of the United States (POTUS) is the head of state and head of government of the United States of America and the commander-in-chief of the United States Armed Forces. The president is also the head of the executive branch of the federal government of the United States and is the chairman of the presidential cabinet.\\n\\nJoe Biden is the 46th and current president of the United States, in office since January 2021.\\n\\nEligibility and requirements\\nArticle II, Section 1, Clause 5 of the constitution states for a person to serve as president must:\\n\\nbe a natural-born citizen of the United States. [note 1]\\nbe at least thirty-five years old.\\nbe a permanent resident in the United States for at least fourteen years.\\nElection process and presidential terms\\nThe president is indirectly elected by the people through the Electoral College to a four-year term, along with the vice presidential candidate and the incumbent vice president of the United States. The presidential candidate or incumbent president must have at least 270 electoral college votes in order to win the election.\\n\\nUnder the Twenty-second amendment to the constitution prevents anyone from being elected president more than twice. This amendment was added after Franklin Roosevelt served four terms from 1933 until his death in 1945.\\n\\nPresident-elect of the United States\\nThe president-elect of the United States is the candidate who has won the United States presidential election and is awaiting inauguration to become the president.\\n\\nPresidential inauguration\\n\\nThe United States Capitol Building, during the inauguration of Joe Biden, January 2021.\\n\\nJoe Biden at his presidential inauguration as he takes the presidential office of office.\\nThe president and vice president-elect immediately began their four-year team on inauguration day every four years on January 20. The original inauguration date was held on March 4, but was later changed in 1933.\\n\\nExecutive Office of the President\\nThe Executive Office of the President consists of the offices and agencies that support the work of the president at the center of the executive branch of the United States federal government. The office consists of several offices and agencies, such as the White House Office, the staff working directly for and reporting to the president, including White House staff, the National Security Council, and the Office of Management and Budget.\\n\\nPresidential line of succession\\nIf the president dies, reigns, or is impeached, the vice president will succeed the presidential office and duties. fifteen other federal government officials also rank in the succession of the president.\\n\\nAbraham Lincoln, James A. Garfield, William McKinley, and John F. Kennedy were assassinated while in office. William Henry Harrison, Zachary Taylor, Warren G. Harding and Franklin Roosevelt died from illness while president. Calvin Coolidge became president, when Warren G. Harding died while in office.\\n\\nRichard Nixon is the only U.S. president to have resigned from office.\\n\\nAndrew Johnson, Bill Clinton, and Donald Trump are the only presidents to have been impeached.',\n",
              "   \"Born in Scranton, Pennsylvania, Biden moved with his family to Delaware in 1953. He studied at the University of Delaware before earning his law degree from Syracuse University. He was elected to the New Castle County Council in 1970 and became the sixth-youngest senator in U.S. history after he was elected in 1972, at age 29. Biden was the chair or ranking member of the Senate Foreign Relations Committee for 12 years. He chaired the Senate Judiciary Committee from 1987 to 1995; drafted and led the effort to pass the Violent Crime Control and Law Enforcement Act and the Violence Against Women Act; and oversaw six U.S. Supreme Court confirmation hearings, including the contentious hearings for Robert Bork and Clarence Thomas. Biden ran unsuccessfully for the Democratic presidential nomination in 1988 and 2008. Barack Obama chose Biden as his running mate in the 2008 and 2012 presidential elections. Biden was a close counselor to Obama during his two terms as Obama's vice president. Biden and his running mate, Kamala Harris, defeated incumbents Donald Trump and Mike Pence in the 2020 presidential election. On January 20, 2021, he became the oldest president in U.S. history, the first to have a female vice president, and the first from Delaware. \\nhttps://en.wikipedia.org/wiki/Joe_Biden\"]],\n",
              " 'uris': None,\n",
              " 'data': None}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each dataset entry, we generate and store an embedding of the combined 'instruction' and 'context' fields, with the context acting as the document for retrieval in our LLM prompts."
      ],
      "metadata": {
        "id": "Lb9njOi7iKTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step 3: leverage LLM to generate response"
      ],
      "metadata": {
        "id": "-GLu6mlriLo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are looking for a version better suited to taking generic instructions in a chat format, we recommend taking a look at Falcon-7B-Instruct."
      ],
      "metadata": {
        "id": "ivBP1rxbpk8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "class Falcon7BInstructModel:\n",
        "\n",
        "    def __init__(self):\n",
        "        # Model name\n",
        "        model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "        # model_name = \"tiiuae/falcon-7b\"\n",
        "        self.pipeline, self.tokenizer = self.initialize_model(model_name) #defined method as below\n",
        "\n",
        "    def initialize_model(self, model_name):\n",
        "        # Tokenizer initialization\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        # Pipeline setup for text generation\n",
        "        pipeline = transformers.pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model_name,\n",
        "            tokenizer=tokenizer,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            trust_remote_code=True,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "\n",
        "        return pipeline, tokenizer\n",
        "\n",
        "    def generate_answer(self, question, context=None):\n",
        "        # Preparing the input prompt\n",
        "        prompt = question if context is None else f\"{context}\\n\\n{question}\"\n",
        "\n",
        "        # Generating responses\n",
        "        sequences = self.pipeline(\n",
        "            prompt,\n",
        "            max_length=500,\n",
        "            do_sample=True,\n",
        "            top_k=10,#sample from top 10 most likely tokens\n",
        "            # top_p = 0.5,\n",
        "            num_return_sequences=1,\n",
        "            eos_token_id=self.tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "        # Extracting and returning the generated text\n",
        "        for seq in sequences:\n",
        "            return seq['generated_text']"
      ],
      "metadata": {
        "id": "YqmkyA7deMDG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key parameters are:\n",
        "\n",
        "Temperature: Controls randomness, higher values increase diversity.\n",
        "\n",
        "Top-p (nucleus): The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus.\n",
        "\n",
        "Top-k: Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens.\n",
        "\n",
        "In general:\n",
        "\n",
        "Higher temperature will make outputs more random and diverse.\n",
        "\n",
        "Lower top-p values reduce diversity and focus on more probable tokens.\n",
        "\n",
        "Lower top-k also concentrates sampling on the highest probability tokens for each step.\n",
        "\n"
      ],
      "metadata": {
        "id": "HXCCrOOgj5IV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **tokenizer** is a key component in natural language processing (NLP) models like Falcon-7B-Instruct. Its primary role is to convert input text into a format that the model can understand. Essentially, it breaks down the text into smaller units called tokens. These tokens can be words, subwords, or even characters, depending on the tokenizer's design. In the context of the Falcon-7B-Instruct model, the AutoTokenizer.from_pretrained(model) call is loading a tokenizer that's specifically designed to work with this model, ensuring that the text is tokenized in a way that aligns with how the model was trained.<br>\n",
        "The **pipeline** in the transformers library is a high-level utility that abstracts away much of the complexity involved in processing data and getting predictions from a model. It handles multiple steps internally, such as tokenizing the input text, feeding the tokens into the model, and then processing the model's output into a human-readable form. In this script, the pipeline is set up for \"text-generation\", which means it's optimized to take in a prompt (like the user question) and generate a continuation of the text based on that prompt."
      ],
      "metadata": {
        "id": "BxBf9aoTkgf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "#this is to address the error of installing git+transoformer command below"
      ],
      "metadata": {
        "id": "E_bNX0z3mUOK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpEG0WkTln5B",
        "outputId": "54486ca3-a66f-47d4-9f27-cbbc52d61d11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-hpnuh6dx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-hpnuh6dx\n",
            "  Resolved https://github.com/huggingface/transformers to commit a564d10afe1a78c31934f0492422700f61a0ffc0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlI49eTmnz9m",
        "outputId": "0f0dd89b-9808-4f09-c229-e79e95b5a0f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->xformers) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->xformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->xformers) (1.3.0)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.26.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the Falcon model class\n",
        "falcon_model = Falcon7BInstructModel()\n",
        "\n",
        "user_question = \"When was Tomoaki Komorida born?\"\n",
        "\n",
        "# Generate an answer to the user question using the LLM\n",
        "answer = falcon_model.generate_answer(user_question)\n",
        "\n",
        "print(f\"Result: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "e0407fc4f9d14ca7915ce0005715f995",
            "9e182362afed46ebaff925f046ad6504",
            "21780d070b7343d7aeaa0b5e8e2a8d10",
            "8d5c4312d4244e46aa1f64e690a291a1",
            "4d0dd2fe51e64440b77fd8969c618660",
            "08f3ce9d9bd943ff860e32b9045875b3",
            "578075bf9bd9488eaacf6c19f91571e7",
            "fc02dabc8e47455e985f72f7d9a889a6",
            "9e516d872963467196f34b8d02374c19",
            "738807d97aa147258579cd083a4b9749",
            "e7fbf95ce2ab4cffabf4526bdc85faaa"
          ]
        },
        "id": "jq6Y_JDukLvY",
        "outputId": "565e864f-d481-4fde-f68b-89ea91c89a74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0407fc4f9d14ca7915ce0005715f995"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'FalconForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: When was Tomoaki Komorida born?\n",
            "I'm sorry, I cannot provide an accurate answer to that question as Tomoaki Komorida, a member of the Japanese professional soccer team Tokyo Verdy F.C., has not been born yet. His birth date is currently listed as August 10, 1988.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**top_p not set**: answer is stict to whether there is exact answer in Vector DB\" <br>\n",
        "**top_p = 0.5**: LLM start to make up some relevant answer but not the one we expect"
      ],
      "metadata": {
        "id": "NBQvfAQ4tdmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = \"What date is U.S. Memorial Day\"\n",
        "\n",
        "# Generate an answer to the user question using the LLM\n",
        "answer = falcon_model.generate_answer(user_question)\n",
        "\n",
        "print(f\"Result: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15kZZb9ekLsx",
        "outputId": "4a3d4d6f-a1f2-4378-e1f0-c15cc631e7bb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: What date is U.S. Memorial Day?\n",
            "U.S. Memorial Day is celebrated on May 30th each year on the last Monday after Memorial Day Weekend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Q&A above all based on pre-trained LLM by default, without incoporating Vector DB reference"
      ],
      "metadata": {
        "id": "jetMLgpNt29w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Incorporating Vector DB knowldege"
      ],
      "metadata": {
        "id": "v4tFrIyZt_t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming vector_store and falcon_model have already been initialized\n",
        "user_question = \"When was Tomoaki Komorida born?\"\n",
        "\n",
        "# Fetch context from VectorStore, assuming it's been populated\n",
        "context_response = vector_store.search_context(user_question)\n",
        "print(context_response['documents'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsGrqntJkLqS",
        "outputId": "52e4b5f5-3bbf-4f08-938c-bc4a963da15b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Komorida was born in Kumamoto Prefecture on July 10, 1981. After graduating from high school, he joined the J1 League club Avispa Fukuoka in 2000. Although he debuted as a midfielder in 2001, he did not play much and the club was relegated to the J2 League at the end of the 2001 season. In 2002, he moved to the J2 club Oita Trinita. He became a regular player as a defensive midfielder and the club won the championship in 2002 and was promoted in 2003. He played many matches until 2005. In September 2005, he moved to the J2 club Montedio Yamagata. In 2006, he moved to the J2 club Vissel Kobe. Although he became a regular player as a defensive midfielder, his gradually was played less during the summer. In 2007, he moved to the Japan Football League club Rosso Kumamoto (later Roasso Kumamoto) based in his local region. He played as a regular player and the club was promoted to J2 in 2008. Although he did not play as much, he still played in many matches. In 2010, he moved to Indonesia and joined Persela Lamongan. In July 2010, he returned to Japan and joined the J2 club Giravanz Kitakyushu. He played often as a defensive midfielder and center back until 2012 when he retired.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the context text from the response\n",
        "# The context is assumed to be in the first element of the 'context' key\n",
        "context = \"\".join(context_response['documents'][0])\n",
        "\n",
        "# Generate an answer using the Falcon model, incorporating the fetched context\n",
        "enriched_answer = falcon_model.generate_answer(user_question, context=context)\n",
        "\n",
        "print(f\"Result: {enriched_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQQAwiF5kLnK",
        "outputId": "43689440-32ba-4b3d-c9bd-b57b41f0b697"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: Komorida was born in Kumamoto Prefecture on July 10, 1981. After graduating from high school, he joined the J1 League club Avispa Fukuoka in 2000. Although he debuted as a midfielder in 2001, he did not play much and the club was relegated to the J2 League at the end of the 2001 season. In 2002, he moved to the J2 club Oita Trinita. He became a regular player as a defensive midfielder and the club won the championship in 2002 and was promoted in 2003. He played many matches until 2005. In September 2005, he moved to the J2 club Montedio Yamagata. In 2006, he moved to the J2 club Vissel Kobe. Although he became a regular player as a defensive midfielder, his gradually was played less during the summer. In 2007, he moved to the Japan Football League club Rosso Kumamoto (later Roasso Kumamoto) based in his local region. He played as a regular player and the club was promoted to J2 in 2008. Although he did not play as much, he still played in many matches. In 2010, he moved to Indonesia and joined Persela Lamongan. In July 2010, he returned to Japan and joined the J2 club Giravanz Kitakyushu. He played often as a defensive midfielder and center back until 2012 when he retired.\n",
            "\n",
            "When was Tomoaki Komorida born? He was born on July 10, 1981. Tomoaki Komorida (Kokorima) will be updated in our celebrity database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the answer was exactly answer based on the help from Vector DB"
      ],
      "metadata": {
        "id": "kSRJagwGvfNB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-BSLfSakLh9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}